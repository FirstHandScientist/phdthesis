\chapter{Introduction}
\label{chapter1}

\section{Privacy Challenge in Cyber-Physical System}
\label{section1.1}
% \begin{figure}[h]
% \center
% \includegraphics[scale=0.4]{./Plots/figure4}
% \caption{Illustration of a CPS.}
% \label{figure1.1}
% \end{figure}
A cyber-physical system (CPS) consists of two major components: a physical process and a cyber system. As shown in Figure \ref{figure1.1}, the physical process, which can be a natural phenomenon or a man-made physical system, is monitored and controlled by the cyber system, which typically is a networked system of several tiny devices with sensing, computation, and communication capabilities \cite{eric2010}. There have been a large number of proposed CPS applications, such as smart house, smart grid, eHealth, assisted living, and etc. They are envisioned to form a smart environment which will greatly benefit the users. A typical CPS often collects a huge amount of privacy-sensitive information for data analysis and decision making. The information enables the system to make smart decisions through sophisticated algorithms. However, a privacy leakage could potentially happen in any stage(s) of data collection, data transmission, data processing, or data storage. On the other hand, there is an increasing demand to protect privacy, e.g., the EU General Data Protection Regulation (GDPR) \cite{gdpr} is to replace the Data Protection Directive 95/46/EC and is designed to harmonize data privacy laws across Europe, to protect and empower all EU citizens data privacy, and to reshape the way organizations across the region approach data privacy. Therefore, research on privacy protection for CPSs attracts much attention nowadays. In the next, researches on privacy protection are briefly reviewed.

\section{Literature Review}
\label{section1.2}
In face of a variety of privacy threats, a large amount of fruitful works have been done. As a conventional privacy-preserving tool, cryptography was reported in many papers, e.g., \cite{stefan2005}, to protect the private data. Although it is an effective method, cryptography is not always applicable because of its demands of high computation capability, high power consumption, and complicated key management. Some studies investigated the privacy-protection in the multi-hop routing, e.g., the reputation-based scheme \cite{cao2006} and the broadcast authentication \cite{liu2005}.

All these aforementioned technologies use additive privacy functionality blocks and cannot protect privacy against the authorized data recipient. GDPR calls for an authorized data recipient to hold and process only the data absolutely necessary for the completion of its duties as well as limiting the access to personal data to those needing to act out the processing \cite{gdpr}. To this end, GDPR advocates the {\textit privacy-by-design} approach which can ``inherently'' preserve privacy through the inclusion of data protection from the onset of the designing of systems rather than an addition afterward. Depending on the physical-layer operations, privacy-by-design approaches can further be categorized into different classes.

%In \cite{shannon1949}, Shannon first pointed out that perfectly secure data transmission can be realized if the key is as long as the encrypted message. 
Until now, most privacy-by-design approaches focus on the data transmission stage, which corresponds to sensing and communication in the physical layer of a CPS. The study on the wire-tap channel \cite{wyner1975} derives the secrecy capacity. Based on the theory of wire-tap channel, people have developed privacy schemes, such as artificial noise \cite{goel2008} and cooperative jamming \cite{tekin2007}. Recently, secure data compression in source coding also attracts much attention \cite{kitti2011}.

% \begin{figure}[h]
% \center
% \includegraphics[scale=0.2]{./Plots/figure28}
% \caption{Illustration of an eHealth network which consists of tiny sensors and a terminal.}
% \label{figure1.2}
% \end{figure}

Besides data transmission, there are other physical-layer operations for a CPS application. Consider the eHealth system in Figure \ref{figure1.2} which consists of wearable or embedded sensors and a handheld terminal. The sensors collect different raw data, e.g., heart rate, body temperature, or blood pressure, process the raw data to make sensor decisions, and then transmit the sensor decisions to the terminal. The terminal makes the final conclusion of the user health condition based on the received sensor decisions. This eHealth CPS operation can be seen as a statistical inference on the user health condition through a sensor network. The statistical inference operation in the physical layer can be modeled as a { hypothesis test}\footnote{Note that there are other terms, e.g., { detection} and { classification}, used to refer to a hypothesis test in many literatures.} or an estimation.

A statistical inference can be done centrally or distributively. The corresponding hypothesis testing theorems have been well established. A brief introduction of the centralized hypothesis testing problems based on the Bayesian approach and Neyman-Pearson approach was presented in \cite{trees2001}. In \cite{varshney1996,tsitsiklis1993}, the basic distributed hypothesis testing problems were summarized of different formulations, topologies, processing and communication constraints. Extended distributed hypothesis testing problems were reviewed in \cite{blum1997}.

When the privacy-by-design approach is used, the privacy-preserving objective is taken into account in the hypothesis tests and the established hypothesis testing theorems need to be revised. There are two pioneering works \cite{marano2009,nadendla2010} which considered a distributed hypothesis testing network in the presence of an eavesdropper. In \cite{marano2009}, the eavesdropper is assumed to be only interested in the data transmission state between the remote decision makers and the fusion center. However, an eavesdropper in reality can be more aggressive and tries to intercept the transmitted information for malicious purposes. When the eavesdropper makes a hypothesis test based on the intercepted decisions of remote decision makers, it has been shown in \cite{nadendla2010} that a likelihood-ratio test (LRT) is an asymptotically optimal decision strategy of a remote decision maker under a constraint on the eavesdropping performance measured by a Kullback-Leibler divergence. Whereas, it was not provided how to design the asymptotically optimal privacy-preserving distributed hypothesis testing network. A recent work \cite{mhanna2015} characterized an achievable rate-error-equivocation region of a distributed hypothesis testing network with communication and privacy constraints. Unfortunately, the converse proof was only given for a special case. Some works devised privacy schemes based on the assumption that the eavesdropper is uninformed of certain parameters. In \cite{nadendla2009,soosahabi2014}, they studied stochastic encryption methods where remote decision makers intentionally generate error to confuse the eavesdropper which is uninformed of the error statistics. Similarly, works \cite{jeon2011,jeon2013} proposed channel aware encryption methods to design the transmission scheme between the remote decision makers and the fusion center based on the channel states which are not known by the eavesdropper.

The privacy issue is also addressed in a distributed estimation context. Some works used a similar method of stochastic encryption, e.g., a stochastic cipher was utilized in \cite{aysal2008} to protect privacy in a network where both the fusion center and eavesdropper make maximum-likelihood estimations. In \cite{guo2017}, the optimal power allocation scheme was studied in a decentralized minimum mean square error estimation susceptible to eavesdropping.

In the aforementioned privacy-by-designs of statistical inference operation in the physical layer, the privacy leakage can also be modeled as a statistical inference made by an eavesdropper or adversary. Besides hypothesis test and estimation, the statistical inference risks have been discussed and evaluated in computer science through the differential privacy. Differential privacy \cite{dwork2006} was proposed to guarantee the statistical privacy by sanitizing mechanisms when an adversary has access to two neighbor databases. In \cite{kairouz2015}, the degradation of the differential privacy level under adaptive interactions was characterized. In \cite{smith2011}, for any statistical estimator and input distribution satisfying a regularity condition, it was proved that there exists a differentially private estimator with the same asymptotic output distribution. In \cite{leny2014}, the methods were developed to approximate a filter by its differentially private version. A survey of the differential privacy in machine learning was given in \cite{ji}. Relations between different formalisms for statistical inference privacy were discussed in \cite{barber}.

% \begin{figure}[h]
% \center
% \subfloat[]{
% \includegraphics[scale=0.5]{./Plots/figure30}\label{figure1.3a}}\\
% \subfloat[]{
% \includegraphics[scale=0.5]{./Plots/figure29}\label{figure1.3b}}
% \caption{Illustration of the smart meter privacy problem and the privacy-by-design approach which exploits renewable energy supplies or an energy storage.}
% \label{figure1.3}
% \end{figure}

Smart grid is one of the most attractive CPS applications. Real-time information about energy demands and advanced control and communication technologies enable more efficient energy generation and distribution in smart grids \cite{tan2013}. Real-time energy demand information is provided to the energy provider by the smart meters installed at consumer premises. While high-resolution meter readings are essential for monitoring and control tasks, they also reveal sensitive private information about the consumers \cite{sultanem1991,andres2010}. A number of privacy-preserving technologies have been developed for the smart meter privacy problem in the recent years. In \cite{fenjun2010}, an encryption method was proposed to protect the privacy of an individual consumer through data aggregation in the neighborhood. In \cite{kalogridis2010}, a privacy scheme was devised by scheduling delay-tolerable appliances to hide the energy demand profiles of others. Most of the literature focuses on the manipulation of meter readings to preserve privacy, e.g., adding a noise sequence on the meter readings. There is a growing interest in guaranteeing privacy by directly altering the energy demands from the energy provider. This can be achieved by an energy management of renewable energy supplies or energy storage charge/discharge flows to filter the real energy demand characteristics. Information-theoretic approaches to these problems have been studied in \cite{tan2013,varodayan2011,gunduz2013,giulio2015}. In these works, the privacy leakage measure is the mutual information rate between the energy demand sequence and the energy supply sequence. The information-theoretic measure can be adopted regardless of the real adversary behavior. However, it lacks an operational meaning. An optimal privacy-preserving energy management of the renewable energy supply or the energy storage charge/discharge is designed to minimize the mutual information rate. Based on the observation that a constant meter reading sequence does not leak any privacy, another privacy-preserving idea was proposed in \cite{lei2014} to utilize an energy storage to minimize the variance of random energy supplies from the energy provider. Similar to the information-theoretic privacy leakage measure, a variance does not have a clear operational meaning. Recently, a hypothesis testing measure of smart meter privacy was proposed in \cite{zuxing20152} and the discussion of a privacy-preserving energy management was based on an infinite-capacity energy storage. The hypothesis testing measure has a clear operational meaning while it limits the adversary behavior to be a hypothesis test. System memory is commonly inevitable in the energy management problems, e.g., the utilization of a finite-capacity energy storage. In \cite{jiyun2013,jiyun2014,simon2015}, a privacy-preserving energy management in the presence of an energy storage was cast to a Markov decision process framework.

\section{Thesis Outline}
\label{section1.3}
The general research question of this work is {how to realize privacy-preserving CPSs}. In this thesis, the privacy-by-design approaches are investigated in the contexts of a distributed sensor network and a smart meter system. The sensing data or the energy data processed in the CPS is driven by a privacy-sensitive unknown physical process, e.g., health condition or life style of the user. A such unknown physical process can be seen as a hypothesis. In this work, hypothesis tests are assumed for the physical-layer operation of a CPS and the privacy leakage. The following questions are to be discussed in the remaining chapters:
% \begin{itemize}
% \item \it How to measure the privacy leakage?
% \item \it Does the optimality of deterministic likelihood-based test (or LRT) hold when the privacy is taken into account?
% \item \it What are the optimality characteristics if a randomized strategy is needed?
% \item \it How to design an optimal privacy-preserving network?
% \item \it How to characterize an optimal privacy-preserving performance (bound)?
% \end{itemize}

\subsection{Chapter \ref{chapter2}}
In this chapter, the basics of hypothesis tests are recapitulated. The Bayesian and Neyman-Pearson hypothesis testing approaches are introduced. The optimality of deterministic likelihood-based test (or LRT) is testified in centralized and distributed hypothesis tests by using the analysis tools of hypothesis testing operation region and person-by-person optimality argument. Depending on the hypothesis testing approach, it is shown that the asymptotic hypothesis testing performance can be characterized by a Kullback-Leibler divergence or a Chernoff information.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% End:
